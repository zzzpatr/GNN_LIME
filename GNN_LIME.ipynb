{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qMNfK27kbyo"
   },
   "source": [
    "Author: Tamirlan Seidakhmetov\n",
    "\n",
    "This colab is built as a part of the CS224W Final Project. The Final Project draft blogpost could be found [here](https://medium.com/@tseidakhmetov/graph-neural-network-based-movie-recommender-system-5876b9686df3) \n",
    "\n",
    "This colab will walk us through building a Movie Recommender System using the Graph Neural Network approach. Specifically, we will employ an [Inductive Graph Based Matrix Completion](https://openreview.net/pdf?id=ByxxgCEYDS) (IGMC) framework introduced at the ICLR 2020 conference. The code structure has been inspired/adapted from the paper's official [Github page](https://github.com/muhanzhang/IGMC.git).\n",
    "\n",
    "First, we start by installing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k-yaCtfGSx79"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch_geometric==2.0.1\n",
    "!pip install torch_scatter -f https://data.pyg.org/whl/torch-1.10.0+cu117.html\n",
    "!pip install torch_sparse -f https://data.pyg.org/whl/torch-1.10.0+cu117.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgRPTJ0q9LqK"
   },
   "source": [
    "Next, we clone the public Github code that will help us download the data and do some preprocessing. We move the required files outside of the cloned folder to use them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Uuh4Sp-jkiD",
    "outputId": "77c3471c-7946-41e1-8a0f-88ff2538a41e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'IGMC' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b latest https://github.com/muhanzhang/IGMC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6Ge1Vqzoj-xg"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "files_to_move = ['util_functions.py', 'data_utils.py', 'preprocessing.py']\n",
    "for f in files_to_move:\n",
    "  if not os.path.exists(f):\n",
    "    shutil.move(os.path.join('IGMC', f), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cpu\n",
      "True\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.rand(3,4)\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "# Device tensor is stored on: cpu\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "#True\n",
    "\n",
    "tensor = tensor.to('cuda')\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "# Device tensor is stored on: cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YnwLa71nSiY1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "from util_functions import *\n",
    "from data_utils import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9kJjP0YLfvz"
   },
   "source": [
    "Define the variables: learning rate, epochs, and batch size.\n",
    "LR_DECAY_STEP and LR_DECAY_VALUE help decrease the learning rate over time to improve the training process/\n",
    "In the original experiment, I've trained the model for 80 epochs, here replacing it by 5 for the code to run fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-bYTIuSwUobd"
   },
   "outputs": [],
   "source": [
    "# Arguments\n",
    "EPOCHS=2\n",
    "BATCH_SIZE=50\n",
    "LR=1e-3\n",
    "LR_DECAY_STEP = 20\n",
    "LR_DECAY_VALUE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sui3tE2jL0C2"
   },
   "source": [
    "Define a seed, it will help with the reporoducibility of the results. In addition, define a device (cpu vs. cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdyLvfBPU_Vs",
    "outputId": "81c29b0a-42a3-4515-ca62-4860afdfdd82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "    torch.cuda.synchronize()\n",
    "    device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSMENitdMIAa"
   },
   "source": [
    "Use the code from the GitHub to download and clean the MovieLens 100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ln9Rsz2mUtEw",
    "outputId": "627d6124-ed66-4ea3-879b-961aaacac6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features shape: (943, 23)\n",
      "Item features shape: (1682, 18)\n"
     ]
    }
   ],
   "source": [
    "(u_features, v_features, adj_train, train_labels, train_u_indices, train_v_indices, val_labels, \n",
    "val_u_indices, val_v_indices, test_labels, test_u_indices, test_v_indices, class_values\n",
    ") = load_official_trainvaltest_split('ml_100k', testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M23jVjpfMbuv"
   },
   "source": [
    "Next, we use the predefined code from the Github to extract an enclosing subgraph for a given graph G. This step was described in details in the section 2 of the Medium Blogpost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXPLokDtSpZG",
    "outputId": "ebe77596-3a26-4d94-cafd-b86d5e76eaba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = eval('MyDynamicDataset')(root='data/ml_100k/testmode/train', A=adj_train, \n",
    "    links=(train_u_indices, train_v_indices), labels=train_labels, h=1, sample_ratio=1.0, \n",
    "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
    "test_dataset = eval('MyDynamicDataset')(root='data/ml_100k/testmode/test', A=adj_train, \n",
    "    links=(test_u_indices, test_v_indices), labels=test_labels, h=1, sample_ratio=1.0, \n",
    "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmm2ZA8LNt7m"
   },
   "source": [
    "Now, we define the IGMC model architecture. It consists of several steps: \n",
    "\n",
    "1.  Optionally add the graph-level dropout layer. It randomly drops edges from the graph, helping avoid overfitting and making the model more robust.\n",
    "2. The message passing layer that extracts node information for each node in the subgraph. As proposed in the table, we implement it using R-GCN layer to handle different edge types. \n",
    "3. Pass it through the tanh non-linearity\n",
    "4. We stack the outputs of step 2 and 3 at each message passing layer\n",
    "5. Concatenate the node representations at each layer in the final node representation h. \n",
    "6. Pull the graph level features g by concatenating target user and item representations. \n",
    "7. Add a linear layer, ReLU non-linearity, Dropout to avoid overfitting, and final linear layer\n",
    "\n",
    "All the model parameters were chosen following the IGMC paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F6QN6-_xUzlJ"
   },
   "outputs": [],
   "source": [
    "class IGMC(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IGMC, self).__init__()\n",
    "        self.rel_graph_convs = torch.nn.ModuleList()\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=4, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.rel_graph_convs.append(RGCNConv(in_channels=32, out_channels=32, num_relations=5, num_bases=4))\n",
    "        self.linear_layer1 = Linear(256, 128)\n",
    "        self.linear_layer2 = Linear(128, 1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.linear_layer1.reset_parameters()\n",
    "        self.linear_layer2.reset_parameters()\n",
    "        for i in self.rel_graph_convs:\n",
    "            i.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        num_nodes = len(data.x)\n",
    "        edge_index_dr, edge_type_dr = dropout_adj(data.edge_index, data.edge_type, p=0.2, num_nodes=num_nodes, training=self.training)\n",
    "\n",
    "        out = data.x\n",
    "        h = []\n",
    "        for conv in self.rel_graph_convs:\n",
    "            out = conv(out, edge_index_dr, edge_type_dr)\n",
    "            out = torch.tanh(out)\n",
    "            h.append(out)\n",
    "        h = torch.cat(h, 1)\n",
    "        h = [h[data.x[:, 0] == True], h[data.x[:, 1] == True]]\n",
    "        g = torch.cat(h, 1)\n",
    "        out = self.linear_layer1(g)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        out = self.linear_layer2(out)\n",
    "        out = out[:,0]\n",
    "        return out\n",
    "\n",
    "model = IGMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjVO8ZTiR1pM"
   },
   "source": [
    "Use a DataLoader to prepare train and test data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Zfc33AIU3Yr",
    "outputId": "7fbf2963-fcdb-490f-d551-c0c7507b8aa2"
   },
   "outputs": [],
   "source": [
    "train_loader = loader.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = loader.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgIzk0jhSIn-"
   },
   "source": [
    "Make sure model is using GPU. Reset the model parameters and define the optimizer. We are using Adam optimizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G2xlebsTU6AS"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.reset_parameters()\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HIJ1i3dSR7F"
   },
   "source": [
    "Train the model for number of epochs defined at the beginning.\n",
    "At each epoch we predict the labels for the batch, find the training MSE loss, do the backpropagation step and update the learnable parameters. Print the training loss at each epoch.\n",
    "\n",
    "After each LR_DECAY_STEP we decrease the learning rate by a factor of LR_DECAY_VALUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fxVBybWU7cU",
    "outputId": "7a3bf1bb-a80c-4170-e767-3c3cd431cf1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ; train loss 1.291838497892022\n",
      "epoch 2 ; train loss 1.0968644388765096\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss_all = 0\n",
    "    for train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        train_batch = train_batch.to(device)\n",
    "        y_pred = model(train_batch)\n",
    "        y_true = train_batch.y\n",
    "        train_loss = F.mse_loss(y_pred, y_true)\n",
    "        train_loss.backward()\n",
    "        train_loss_all += BATCH_SIZE * float(train_loss)\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "    train_loss_all = train_loss_all / len(train_loader.dataset)\n",
    "    \n",
    "    print('epoch', epoch,'; train loss', train_loss_all)\n",
    "\n",
    "    if epoch % LR_DECAY_STEP == 0:\n",
    "      for param_group in optimizer.param_groups:\n",
    "          param_group['lr'] = param_group['lr'] / LR_DECAY_VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTIjyHN-S061"
   },
   "source": [
    "Assess the performance of the model using the test set by predicting the labels and finding a MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPFRkqadVH5v",
    "outputId": "b079f76a-9b10-497e-b595-e3a1f1eaec89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE loss 0.91720458984375\n",
      "test RMSE loss 0.9577079877727604\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "for test_batch in test_loader:\n",
    "    test_batch = test_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(test_batch)\n",
    "    y_true = test_batch.y\n",
    "    test_loss += F.mse_loss(y_pred, y_true, reduction='sum')\n",
    "    # torch.cuda.empty_cache()\n",
    "mse_loss = float(test_loss) / len(test_loader.dataset)\n",
    "\n",
    "print('test MSE loss', mse_loss)\n",
    "print('test RMSE loss', math.sqrt(mse_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_test = pd.read_csv(\"raw_data/ml_100k/u1.test\", sep=\"\\t\",header=None)\n",
    "all_train = pd.read_csv(\"raw_data/ml_100k/u1.base\", sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user = pd.read_csv(\"raw_data/ml_100k/u.user\", sep=\"|\",header=None)\n",
    "all_item = pd.read_table(\"raw_data/ml_100k/u.item\",sep='|',encoding='latin-1',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< choose link >>\n",
      "268 641 predicted score: 2.21 real score: 2\n",
      "-user\n",
      "[31 'F' 'librarian']\n",
      "-movie\n",
      "Grifters, The (1990)\n",
      "\n",
      "<< rank 1 >>\n",
      "84 7 3\n",
      "-user\n",
      "[51 'M' 'educator']\n",
      "-movie\n",
      "Babe (1995)\n",
      "\n",
      "<< rank 2 >>\n",
      "37 423 2\n",
      "-user\n",
      "[28 'F' 'other']\n",
      "-movie\n",
      "Children of the Corn: The Gathering (1996)\n",
      "\n",
      "<< rank 3 >>\n",
      "12 401 3\n",
      "-user\n",
      "[47 'M' 'educator']\n",
      "-movie\n",
      "Ghost (1990)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "choose_link = 12241 ## choose your interest link\n",
    "random_X_l = []\n",
    "lime_diff_l = []\n",
    "\n",
    "print(\"<< choose link >>\")\n",
    "print(test_u_indices[choose_link],test_v_indices[choose_link],\n",
    "      \"predicted score:\",np.round(model(ori_link).cpu().detach().numpy()[0],2),\"real score:\",test_labels[choose_link])\n",
    "print(\"-user\")\n",
    "print(all_user.loc[test_u_indices[choose_link],[1,2,3]].values)\n",
    "print(\"-movie\")\n",
    "print(all_item.loc[test_v_indices[choose_link],1])\n",
    "print(\"\")\n",
    "\n",
    "## save old link\n",
    "ori_link = test_dataset[choose_link].to(device)\n",
    "old_edge_index = ori_link.edge_index.cpu().detach().numpy()\n",
    "old_edge_type = ori_link.edge_type.cpu().detach().numpy()\n",
    "test_dataset_sep = eval('MyDynamicDataset')(root='data/ml_100k/testmode/test', A=adj_train, \n",
    "    links=(test_u_indices, test_v_indices), labels=test_labels, h=1, sample_ratio=1.0, \n",
    "    max_nodes_per_hop=200, u_features=None, v_features=None, class_values=class_values)\n",
    "\n",
    "## multiple link permutations\n",
    "for i in range(1000):\n",
    "\n",
    "    \n",
    "    sep_link = old_edge_type.copy()\n",
    "    random_X = np.random.randint(2, size=len(sep_link))\n",
    "    ## sample 0 / 1 , if 0 score set to 2 (assume middle doesn't matter) \n",
    "    sep_link[np.where(random_X == 0)[0]] = 2\n",
    "    sep_dataset = test_dataset_sep[choose_link]\n",
    "    sep_dataset.edge_index = torch.tensor(old_edge_index)\n",
    "    sep_dataset.edge_type = torch.tensor(sep_link)\n",
    "    adjust_link = sep_dataset.to(device)\n",
    "    lime_diff = 4- np.abs((model(adjust_link)-model(ori_link)).cpu().detach().numpy()[0])\n",
    "    random_X_l.append(random_X)\n",
    "    lime_diff_l.append(lime_diff)\n",
    "\n",
    "## Lasso X = link permutations , y = difference between model predict original link and adjust link\n",
    "lime_df = pd.DataFrame(random_X_l)\n",
    "lime_df[\"y\"] = lime_diff_l\n",
    "lr = linear_model.Lasso(alpha=0.001, max_iter=500)\n",
    "lr.fit(lime_df.drop(\"y\",axis=1),lime_df[\"y\"])\n",
    "imp_index = pd.DataFrame(np.abs(lr.coef_)).sort_values(by=0,ascending=False).index[:3]\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"<< rank\",i+1,\">>\")\n",
    "    imp_link = imp_index[i]\n",
    "    print(test_u_indices[imp_link],test_v_indices[imp_link],test_labels[imp_link])\n",
    "    print(\"-user\")\n",
    "    print(all_user.loc[test_u_indices[imp_link],[1,2,3]].values)\n",
    "    print(\"-movie\")\n",
    "    print(all_item.loc[test_v_indices[imp_link],1])\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
